
Use GPU: 0 for training
==> training...
/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  cpuset_checked))
/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  cpuset_checked))
Epoch: [1][0/426]	GPU 0	Time: 14.532	Loss 0.6708	Acc@1 78.125	Acc@5 100.000	Precision 0.000	Recall 0.000	
Epoch: [1][200/426]	GPU 0	Time: 74.706	Loss 0.5161	Acc@1 75.466	Acc@5 100.000	Precision 0.634	Recall 0.516	
Epoch: [1][400/426]	GPU 0	Time: 142.021	Loss 0.4984	Acc@1 76.578	Acc@5 100.000	Precision 0.659	Recall 0.547	
/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  cpuset_checked))
 * Epoch 1, Acc@1 76.669, Acc@5 100.000, precision 0.662, recall 0.551, Time 289.84
Test: [0/48]	GPU: 0	Time: 2.808	Loss 0.4722	Acc@1 78.125	Acc@5 100.000	Precision 0.727	Recall 0.421	
 ** Acc@1 79.457, Acc@5 100.000, precision 0.744, recall 0.532
saving the best model!
==> training...
/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  cpuset_checked))
Epoch: [2][0/426]	GPU 0	Time: 5.630	Loss 0.3360	Acc@1 82.812	Acc@5 100.000	Precision 0.739	Recall 0.773	
Epoch: [2][200/426]	GPU 0	Time: 70.613	Loss 0.4550	Acc@1 78.825	Acc@5 100.000	Precision 0.693	Recall 0.594	
Error in sys.excepthook:
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/dist-packages/wandb/sdk/lib/exit_hooks.py", line 46, in exc_handler
    self.exit_code = 1
KeyboardInterrupt
Original exception was:
Traceback (most recent call last):
  File "train_teacher.py", line 287, in <module>
    main()
  File "train_teacher.py", line 113, in main
    main_worker(None if ngpus_per_node > 1 else opt.gpu_id, ngpus_per_node, opt)
  File "train_teacher.py", line 207, in main_worker
    train_acc, train_acc_top5, train_loss, precision, recall = train(epoch, train_loader, model, criterion, optimizer, opt)
  File "/content/drive/.shortcut-targets-by-id/1aAWk40Gy3z7CoH8LjUDuJOtYT0RfUzYr/CSE499/SimKD/helper/loops.py", line 24, in train_vanilla
    for idx, batch_data in enumerate(train_loader):
  File "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py", line 652, in __next__
    data = self._next_data()
  File "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py", line 1330, in _next_data
    idx, data = self._get_data()
  File "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py", line 1296, in _get_data
    success, data = self._try_get_data()
  File "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py", line 1134, in _try_get_data
    data = self._data_queue.get(timeout=timeout)
  File "/usr/lib/python3.7/multiprocessing/queues.py", line 104, in get
    if not self._poll(timeout):
  File "/usr/lib/python3.7/multiprocessing/connection.py", line 257, in poll
    return self._poll(timeout)
  File "/usr/lib/python3.7/multiprocessing/connection.py", line 414, in _poll
    r = wait([self], timeout)
  File "/usr/lib/python3.7/multiprocessing/connection.py", line 921, in wait
    ready = selector.select(timeout)
  File "/usr/lib/python3.7/selectors.py", line 415, in select
    fd_event_list = self._selector.poll(timeout)
KeyboardInterrupt